#!/usr/bin/env python3
"""
PIPELINE COMPLET - Version finale corrigÃ©e
GÃ¨re l'upload dans HDFS et le traitement des commandes
"""

import os
import subprocess
import json
import csv
import uuid
import argparse
from datetime import datetime, timedelta
from pathlib import Path

class Config:
    """Configuration globale"""
    BASE_LOCAL_DATA = os.path.abspath("../data")
    HDFS_RAW_ORDERS = "/raw/orders"
    HDFS_RAW_STOCK = "/raw/stock"
    CONTAINER_TMP = "/tmp/data_today"
    OUTPUT_DIR = Path("./supplier_orders")
    OUTPUT_DIR.mkdir(exist_ok=True)
    
    @staticmethod
    def get_today():
        """Retourne la date du jour au format YYYY-MM-DD"""
        return datetime.now().strftime("%Y-%m-%d")

class HDFSUploader:
    """GÃ¨re l'upload des fichiers vers HDFS"""
    
    def __init__(self, target_date=None):
        self.target_date = target_date or Config.get_today()
        self.copied_files = []
    
    def run_cmd(self, cmd):
        """ExÃ©cute une commande"""
        print(f"â†’ {cmd}")
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        if result.returncode != 0:
            error_msg = result.stderr.strip()[:300]
            # Ignorer les avertissements SASL
            if "SASL" in error_msg and "trust check" in error_msg:
                print(f"âš ï¸  Avertissement SASL (normal)")
            elif "No such file or directory" in error_msg and "find" in cmd:
                # Ignorer les erreurs find pour les dossiers vides
                print(f"â„¹ï¸  Aucun fichier trouvÃ© (normal si premier upload)")
            else:
                print(f"âŒ Erreur: {error_msg}")
        elif result.stdout.strip():
            print(f"ğŸ“‹ Sortie: {result.stdout.strip()[:200]}")
        
        return result
    
    def copy_to_container(self):
        """Copie les donnÃ©es vers le conteneur"""
        print(f"\nğŸ“¦ Copie vers le conteneur pour {self.target_date}...")
        
        local_orders = os.path.join(Config.BASE_LOCAL_DATA, "raw_orders", f"date={self.target_date}")
        
        if not os.path.exists(local_orders):
            print(f"âŒ Dossier non trouvÃ©: {local_orders}")
            return []
        
        # Nettoyer le rÃ©pertoire temporaire
        self.run_cmd(f"docker-compose exec namenode rm -rf {Config.CONTAINER_TMP}")
        self.run_cmd(f"docker-compose exec namenode mkdir -p {Config.CONTAINER_TMP}")
        
        # Lister tous les dossiers store_id
        store_dirs = [d for d in os.listdir(local_orders) 
                     if os.path.isdir(os.path.join(local_orders, d)) and d.startswith("store_id=")]
        
        print(f"ğŸ“ {len(store_dirs)} dossiers store_id Ã  copier")
        
        self.copied_files = []
        
        for store_dir in store_dirs:
            store_id = store_dir.split("=")[1]
            local_file = os.path.join(local_orders, store_dir, "orders.json")
            
            if os.path.exists(local_file):
                # CrÃ©er le rÃ©pertoire dans le conteneur
                container_dir = f"{Config.CONTAINER_TMP}/raw_orders/date={self.target_date}/{store_dir}/"
                self.run_cmd(f"docker-compose exec namenode mkdir -p {container_dir}")
                
                # Copier le fichier
                container_file = f"{container_dir}orders.json"
                result = self.run_cmd(f'docker cp "{local_file}" namenode:{container_file}')
                
                if result.returncode == 0:
                    file_size = os.path.getsize(local_file)
                    print(f"  âœ… {store_id}: {file_size:,} bytes")
                    self.copied_files.append({
                        'store_id': store_id,
                        'container_path': container_file,
                        'size': file_size
                    })
                else:
                    print(f"  âŒ {store_id}: Ã©chec copie")
        
        # VÃ©rifier ce qui a Ã©tÃ© copiÃ©
        print(f"\nğŸ” VÃ©rification fichiers copiÃ©s:")
        self.run_cmd(f"docker-compose exec namenode ls -la {Config.CONTAINER_TMP}/raw_orders/date={self.target_date}/ 2>/dev/null || echo 'RÃ©pertoire vide'")
        
        return self.copied_files
    
    def upload_to_hdfs(self):
        """Upload vers HDFS"""
        print(f"\nğŸš€ Upload vers HDFS pour {self.target_date}...")
        
        if not self.copied_files:
            print("âŒ Aucun fichier Ã  uploader")
            return False
        
        success_count = 0
        
        for file_info in self.copied_files:
            store_id = file_info['store_id']
            source_file = file_info['container_path']
            
            # Chemin HDFS
            hdfs_dir = f"{Config.HDFS_RAW_ORDERS}/date={self.target_date}/store_id={store_id}/"
            hdfs_file = f"{hdfs_dir}orders.json"
            
            print(f"\n  ğŸ“¦ Traitement store_id={store_id}")
            print(f"    Source: {source_file}")
            print(f"    Destination: {hdfs_file}")
            
            # CrÃ©er le rÃ©pertoire HDFS
            mkdir_result = self.run_cmd(f"docker-compose exec namenode hdfs dfs -mkdir -p {hdfs_dir}")
            
            if mkdir_result.returncode != 0:
                print(f"    âŒ Impossible de crÃ©er {hdfs_dir}")
                continue
            
            # Upload le fichier
            upload_result = self.run_cmd(f"docker-compose exec namenode hdfs dfs -copyFromLocal {source_file} {hdfs_file}")
            
            if upload_result.returncode == 0:
                success_count += 1
                print(f"    âœ… Upload rÃ©ussi")
                
                # VÃ©rification rapide
                self.run_cmd(f"docker-compose exec namenode hdfs dfs -test -e {hdfs_file} && echo '    âœ… Fichier prÃ©sent dans HDFS' || echo '    âŒ Fichier absent'")
            else:
                print(f"    âŒ Ã‰chec upload")
        
        print(f"\nğŸ“Š RÃ©sultat: {success_count}/{len(self.copied_files)} fichiers uploadÃ©s")
        return success_count > 0
    
    def verify_hdfs_upload(self):
        """VÃ©rification de l'upload HDFS"""
        print(f"\nğŸ” VÃ©rification HDFS pour {self.target_date}...")
        
        # VÃ©rifier le rÃ©pertoire date
        self.run_cmd(f"docker-compose exec namenode hdfs dfs -test -d {Config.HDFS_RAW_ORDERS}/date={self.target_date} && echo 'âœ… RÃ©pertoire date prÃ©sent' || echo 'âŒ RÃ©pertoire date absent'")
        
        # Lister les fichiers
        print(f"\nğŸ“ Fichiers dans HDFS:")
        self.run_cmd(f"docker-compose exec namenode hdfs dfs -ls -R {Config.HDFS_RAW_ORDERS}/date={self.target_date} 2>/dev/null || echo 'Aucun fichier pour cette date'")
        
        # Compter
        print(f"\nğŸ”¢ Nombre de fichiers:")
        self.run_cmd(f"docker-compose exec namenode hdfs dfs -ls {Config.HDFS_RAW_ORDERS}/date={self.target_date} 2>/dev/null | grep -c '^' || echo '0'")
        
        return True
    
    def sync_hive_partitions(self):
        """Synchronise les partitions Hive"""
        print("\nğŸ”„ Synchronisation Hive...")
        
        self.run_cmd('docker-compose exec trino trino --execute "CALL hive.system.sync_partition_metadata(\'procurement\', \'orders_raw\', \'FULL\')"')
        self.run_cmd('docker-compose exec trino trino --execute "CALL hive.system.sync_partition_metadata(\'procurement\', \'stock_raw\', \'FULL\')"')
        
        print("âœ… Synchronisation terminÃ©e")
        return True
    
    def run_upload_pipeline(self):
        """ExÃ©cute le pipeline complet d'upload"""
        print(f"\n{'='*80}")
        print(f"HDFS UPLOAD PIPELINE")
        print(f"Date: {self.target_date}")
        print(f"{'='*80}")
        
        try:
            # 1. Copie vers le conteneur
            copied = self.copy_to_container()
            if not copied:
                print("âŒ Aucun fichier Ã  copier")
                return False
            
            # 2. Upload vers HDFS
            uploaded = self.upload_to_hdfs()
            if not uploaded:
                print("âŒ Ã‰chec de l'upload")
                return False
            
            # 3. VÃ©rification
            self.verify_hdfs_upload()
            
            # 4. Synchronisation Hive
            self.sync_hive_partitions()
            
            print(f"\nâœ… Upload HDFS terminÃ© avec succÃ¨s")
            return True
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'upload: {e}")
            import traceback
            traceback.print_exc()
            return False

class ProcurementGenerator:
    """GÃ©nÃ¨re les commandes fournisseurs"""
    
    def __init__(self, target_date='2025-12-02'):
        self.target_date = target_date
        self.output_dir = Config.OUTPUT_DIR
        
    def run_trino_query_jsonl(self, query):
        """ExÃ©cute une requÃªte Trino et parse le JSONL"""
        cmd = ['docker-compose', 'exec', '-T', 'trino', 'trino', '--output-format', 'JSON', '--execute', query]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, timeout=30)
            
            if not result.stdout.strip():
                return []
            
            # Parser le JSONL (une ligne = un objet JSON)
            data = []
            for line in result.stdout.strip().split('\n'):
                if line.strip():
                    try:
                        data.append(json.loads(line))
                    except json.JSONDecodeError:
                        continue
            
            return data
            
        except subprocess.CalledProcessError as e:
            print(f"Erreur Trino: {e.stderr}")
            return []
        except Exception as e:
            print(f"Erreur: {e}")
            return []
    
    def get_aggregated_demand(self):
        """RÃ©cupÃ¨re la demande agrÃ©gÃ©e"""
        print(f"1. Calcul de la demande pour {self.target_date}...")
        
        query = f"""
        SELECT 
            sku_id,
            SUM(CAST(quantity AS INTEGER)) as total_demand,
            COUNT(*) as order_count
        FROM hive.procurement.orders_raw 
        WHERE date = '{self.target_date}'
        AND sku_id IS NOT NULL
        GROUP BY sku_id
        HAVING SUM(CAST(quantity AS INTEGER)) > 0
        ORDER BY total_demand DESC
        """
        
        data = self.run_trino_query_jsonl(query)
        print(f"   âœ… {len(data)} SKU avec demande")
        
        if data:
            print(f"   Exemple: {data[0].get('sku_id')} - {data[0].get('total_demand')} unitÃ©s")
        
        return data
    
    def get_stock_data(self):
        """RÃ©cupÃ¨re les donnÃ©es de stock"""
        print(f"2. RÃ©cupÃ©ration du stock pour {self.target_date}...")
        
        query = f"""
        SELECT 
            sku_id,
            CAST(available_stock AS INTEGER) as available_stock,
            CAST(reserved_stock AS INTEGER) as reserved_stock,
            CAST(safety_stock AS INTEGER) as safety_stock
        FROM hive.procurement.stock_raw 
        WHERE date = '{self.target_date}'
        AND sku_id IS NOT NULL
        """
        
        data = self.run_trino_query_jsonl(query)
        print(f"   âœ… {len(data)} Ã©lÃ©ments de stock trouvÃ©s")
        
        if data:
            print(f"   Exemple: SKU={data[0].get('sku_id')}, Stock={data[0].get('available_stock')}")
        
        return data
    
    def get_products_with_suppliers(self):
        """RÃ©cupÃ¨re les produits avec leurs fournisseurs"""
        print("3. RÃ©cupÃ©ration des produits et fournisseurs...")
        
        query = """
        SELECT 
            p.sku_id,
            p.product_name,
            CAST(p.unit_price AS DOUBLE) as unit_price,
            COALESCE(p.pack_size, 1) as pack_size,
            COALESCE(p.min_order_quantity, 0) as min_order_quantity,
            ps.supplier_id,
            COALESCE(ps.lead_time_days, 7) as lead_time_days,
            s.supplier_name
        FROM postgresql.public.products p
        JOIN postgresql.public.product_supplier ps ON p.sku_id = ps.sku_id AND ps.is_primary = true
        JOIN postgresql.public.suppliers s ON ps.supplier_id = s.supplier_id
        WHERE p.sku_id IS NOT NULL
        """
        
        data = self.run_trino_query_jsonl(query)
        print(f"   âœ… {len(data)} produits avec fournisseurs")
        
        if data:
            print(f"   Exemple: {data[0].get('sku_id')} - {data[0].get('product_name')[:20]}...")
        
        return data
    
    def calculate_orders(self, demand_data, stock_data, product_data):
        """Calcule les commandes avec affichage dÃ©taillÃ© des calculs"""
        print("4. Calcul des commandes...")
        print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print("   FORMULE DE CALCUL :")
        print("   Demande Nette = MAX(0, Demande Client + Stock SÃ©curitÃ© - Stock Disponible)")
        print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        
        # CrÃ©er des dictionnaires pour un accÃ¨s rapide
        demand_dict = {}
        for item in demand_data:
            sku = item.get('sku_id')
            if sku:
                demand_dict[sku] = {
                    'total_demand': int(item.get('total_demand', 0)),
                    'order_count': int(item.get('order_count', 0))
                }
        
        stock_dict = {}
        for item in stock_data:
            sku = item.get('sku_id')
            if sku:
                try:
                    stock_dict[sku] = {
                        'available_stock': int(float(item.get('available_stock', 50))),
                        'reserved_stock': int(float(item.get('reserved_stock', 0))),
                        'safety_stock': int(float(item.get('safety_stock', 10)))
                    }
                except:
                    stock_dict[sku] = {
                        'available_stock': 50,
                        'reserved_stock': 0,
                        'safety_stock': 10
                    }
        
        product_dict = {}
        for item in product_data:
            sku = item.get('sku_id')
            if sku:
                product_dict[sku] = item
        
        # Calculer les commandes
        orders = []
        
        print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
        print("   â”‚ DÃ‰TAIL DES CALCULS PAR SKU                                                          â”‚")
        print("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        print("   â”‚     SKU      â”‚ Demande  â”‚ Stock Disp.  â”‚ Stock Secur. â”‚ Besoin Net   â”‚ RÃ©sultat     â”‚")
        print("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
        
        orders_count = 0
        no_order_count = 0
        
        for sku_id, product in product_dict.items():
            if sku_id not in demand_dict:
                continue  # Pas de demande pour ce produit
            
            demand = demand_dict[sku_id]['total_demand']
            stock = stock_dict.get(sku_id, {
                'available_stock': 50,
                'reserved_stock': 0,
                'safety_stock': 10
            })
            
            # CALCUL DE LA DEMANDE NETTE
            available = stock['available_stock'] - stock['reserved_stock']
            net_demand = max(0, demand + stock['safety_stock'] - available)
            
            # Afficher le calcul
            print(f"   â”‚ {sku_id:<12} â”‚ {demand:<8} â”‚ {available:<12} â”‚ {stock['safety_stock']:<12} â”‚ {net_demand:<12} â”‚", end="")
            
            if net_demand > 0:
                # Appliquer les rÃ¨gles mÃ©tier
                pack_size = max(1, int(product.get('pack_size', 1)))
                min_order_qty = int(product.get('min_order_quantity', 0))
                
                # Arrondir au pack supÃ©rieur
                packs_needed = max(1, (net_demand + pack_size - 1) // pack_size)
                order_quantity = packs_needed * pack_size
                
                # Respecter la quantitÃ© minimale
                if min_order_qty > 0 and order_quantity < min_order_qty:
                    order_quantity = min_order_qty
                
                # CrÃ©er la commande
                order_id = str(uuid.uuid4())
                unit_price = float(product.get('unit_price', 0))
                
                order_item = {
                    'order_id': order_id,
                    'order_date': self.target_date,
                    'supplier_id': product.get('supplier_id'),
                    'supplier_name': product.get('supplier_name'),
                    'sku_id': sku_id,
                    'product_name': product.get('product_name'),
                    'demand': demand,
                    'available_stock': stock['available_stock'],
                    'reserved_stock': stock['reserved_stock'],
                    'safety_stock': stock['safety_stock'],
                    'net_demand': net_demand,
                    'order_quantity': order_quantity,
                    'pack_size': pack_size,
                    'unit_price': unit_price,
                    'total_price': unit_price * order_quantity,
                    'lead_time_days': int(product.get('lead_time_days', 7)),
                    'calculated_at': datetime.now().isoformat(),
                    'calculation_details': {
                        'formula': 'max(0, demand + safety_stock - available_stock)',
                        'demand': demand,
                        'safety_stock': stock['safety_stock'],
                        'available_stock': available,
                        'calculation': f"max(0, {demand} + {stock['safety_stock']} - {available}) = {net_demand}"
                    }
                }
                
                orders.append(order_item)
                orders_count += 1
                print(f" COMMANDE {order_quantity} unitÃ©s â”‚")
                
            else:
                no_order_count += 1
                print(f" PAS DE COMMANDE     â”‚")
        
        print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        print("\n   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print("   RÃ‰SUMÃ‰ DES CALCULS :")
        print(f"   â€¢ {orders_count} SKU nÃ©cessitent une commande")
        print(f"   â€¢ {no_order_count} SKU n'ont pas besoin de commande (stock suffisant)")
        
        if orders_count > 0 and len(orders) > 0:
            print("\n   EXEMPLES DE CALCULS DÃ‰TAILLÃ‰S :")
            print("   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
            
            for i, order in enumerate(orders[:3]):  # Juste les 3 premiers
                details = order['calculation_details']
                print(f"   Exemple {i+1} - {order['sku_id']}:")
                print(f"     Formule : {details['formula']}")
                print(f"     Calcul  : {details['calculation']}")
                print(f"     DÃ©tail  : Demande({details['demand']}) + SÃ©curitÃ©({details['safety_stock']}) - Disponible({details['available_stock']}) = {order['net_demand']}")
                print()
        
        print(f"   âœ… {len(orders)} articles Ã  commander")
        return orders
    
    def generate_supplier_files(self, orders):
        """GÃ©nÃ¨re les fichiers par fournisseur"""
        print("5. GÃ©nÃ©ration des fichiers fournisseurs...")
        
        if not orders:
            print("   âš ï¸  Aucune commande Ã  gÃ©nÃ©rer")
            return 0
        
        # Regrouper par fournisseur
        suppliers = {}
        for order in orders:
            supplier_id = order['supplier_id']
            if supplier_id not in suppliers:
                suppliers[supplier_id] = {
                    'supplier_name': order['supplier_name'],
                    'orders': []
                }
            suppliers[supplier_id]['orders'].append(order)
        
        # GÃ©nÃ©rer les fichiers
        files_generated = 0
        
        for supplier_id, data in suppliers.items():
            safe_id = supplier_id.replace('/', '_')
            
            # Fichier JSON
            json_file = self.output_dir / f"supplier_{safe_id}_{self.target_date}.json"
            try:
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump({
                        'supplier_id': supplier_id,
                        'supplier_name': data['supplier_name'],
                        'order_date': self.target_date,
                        'total_items': len(data['orders']),
                        'total_value': sum(o['total_price'] for o in data['orders']),
                        'generated_at': datetime.now().isoformat(),
                        'items': data['orders']
                    }, f, indent=2, ensure_ascii=False)
                
                # Fichier CSV
                csv_file = self.output_dir / f"supplier_{safe_id}_{self.target_date}.csv"
                with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.writer(f)
                    writer.writerow(['SKU', 'PRODUIT', 'DEMANDE', 'STOCK_DISPONIBLE', 'STOCK_SECURITE', 
                                    'BESOIN_NET', 'QUANTITE_COMMANDEE', 'TAILLE_PACK', 'PRIX_UNITAIRE', 'TOTAL'])
                    
                    for order in data['orders']:
                        writer.writerow([
                            order['sku_id'],
                            order['product_name'],
                            order['demand'],
                            order['available_stock'],
                            order['safety_stock'],
                            order['net_demand'],
                            order['order_quantity'],
                            order['pack_size'],
                            f"{order['unit_price']:.2f}",
                            f"{order['total_price']:.2f}"
                        ])
                
                files_generated += 2
                total_value = sum(o['total_price'] for o in data['orders'])
                print(f"   âœ… {supplier_id}: {len(data['orders'])} articles, {total_value:.2f}â‚¬")
                
            except Exception as e:
                print(f"   âŒ Erreur pour {supplier_id}: {e}")
        
        return files_generated
    
    def store_in_cassandra(self, orders):
        """Stocke les rÃ©sultats dans Cassandra"""
        print("6. Stockage dans Cassandra...")
        
        if not orders:
            return
        
        stored_count = 0
        
        for order in orders[:20]:  # Limiter pour ne pas surcharger
            try:
                query = f"""
                INSERT INTO procurement.supplier_orders (
                    order_date, supplier_id, order_id, sku_id,
                    quantity, status, generated_at
                ) VALUES (
                    '{self.target_date}', '{order['supplier_id']}', '{order['order_id']}', '{order['sku_id']}',
                    {order['order_quantity']}, 'GENERATED', toTimestamp(now())
                );
                """
                
                cmd = ['docker-compose', 'exec', '-T', 'cassandra', 'cqlsh', '-e', query]
                result = subprocess.run(cmd, capture_output=True, text=True, check=False)
                
                if result.returncode == 0:
                    stored_count += 1
                    
            except Exception as e:
                print(f"   âš ï¸  Erreur Cassandra pour {order['sku_id']}: {e}")
        
        print(f"   âœ… {stored_count} commandes stockÃ©es dans Cassandra")
        
    def run_processing_pipeline(self):
        """ExÃ©cute le pipeline complet de traitement"""
        print(f"\n{'='*80}")
        print(f"PROCESSING PIPELINE")
        print(f"Date: {self.target_date}")
        print(f"{'='*80}\n")
        
        try:
            # Ã‰tape 1: Demande
            demand_data = self.get_aggregated_demand()
            if not demand_data:
                print("âŒ Aucune demande trouvÃ©e")
                return False
            
            # Ã‰tape 2: Stock
            stock_data = self.get_stock_data()
            
            # Ã‰tape 3: Produits
            product_data = self.get_products_with_suppliers()
            if not product_data:
                print("âŒ Aucun produit trouvÃ©")
                return False
            
            # Ã‰tape 4: Calcul
            orders = self.calculate_orders(demand_data, stock_data, product_data)
            
            if not orders:
                print(f"\n{'='*60}")
                print("â„¹ï¸  AUCUNE COMMANDE NÃ‰CESSAIRE")
                print("   Raison : Stock suffisant pour couvrir la demande + sÃ©curitÃ©")
                print(f"{'='*60}")
                return True  # C'est un succÃ¨s, pas une erreur
            
            # Ã‰tape 5: GÃ©nÃ©ration fichiers
            files_count = self.generate_supplier_files(orders)
            
            # Ã‰tape 6: Cassandra
            self.store_in_cassandra(orders)
            
            # Rapport final
            print(f"\n{'='*80}")
            print("âœ… PROCESSING TERMINÃ‰ AVEC SUCCÃˆS")
            print(f"{'='*80}")
            
            total_items = len(orders)
            total_value = sum(o['total_price'] for o in orders)
            supplier_count = len(set(o['supplier_id'] for o in orders))
            
            print(f"\nğŸ“Š RÃ‰SUMÃ‰ DÃ‰TAILLÃ‰:")
            print(f"   Commandes gÃ©nÃ©rÃ©es: {total_items}")
            print(f"   Fournisseurs concernÃ©s: {supplier_count}")
            print(f"   Valeur totale des commandes: {total_value:.2f}â‚¬")
            print(f"   Fichiers gÃ©nÃ©rÃ©s: {files_count}")
            
            # Statistiques
            if orders:
                avg_order_value = total_value / total_items
                avg_quantity = sum(o['order_quantity'] for o in orders) / total_items
                print(f"\nğŸ“ˆ STATISTIQUES:")
                print(f"   Valeur moyenne par article: {avg_order_value:.2f}â‚¬")
                print(f"   QuantitÃ© moyenne commandÃ©e: {avg_quantity:.1f} unitÃ©s")
            
            print(f"\nğŸ“ RÃ©pertoire de sortie: {self.output_dir.absolute()}")
            
            return True
            
        except Exception as e:
            print(f"\n{'='*80}")
            print(f"âŒ ERREUR: {e}")
            print(f"{'='*80}")
            import traceback
            traceback.print_exc()
            return False

class CompletePipeline:
    """Pipeline complet qui combine upload et traitement"""
    
    def __init__(self, target_date=None):
        self.target_date = target_date or Config.get_today()
        self.uploader = HDFSUploader(self.target_date)
        self.processor = ProcurementGenerator(self.target_date)
        self.start_time = datetime.now()
    
    def run(self):
        """ExÃ©cute le pipeline complet"""
        print(f"\n{'='*100}")
        print(f"PIPELINE COMPLET")
        print(f"Date: {self.target_date}")
        print(f"Temps de dÃ©but: {self.start_time.strftime('%H:%M:%S')}")
        print(f"{'='*100}")
        
        # Ã‰TAPE 1: Upload HDFS
        print(f"\n{'='*80}")
        print(f"Ã‰TAPE 1: UPLOAD VERS HDFS")
        print(f"{'='*80}")
        
        upload_success = self.uploader.run_upload_pipeline()
        if not upload_success:
            print("âŒ Ã‰chec de l'upload HDFS, arrÃªt du pipeline")
            return False
        
        # Pause pour laisser Hive se synchroniser
        import time
        print("\nâ³ Attente de 5 secondes pour la synchronisation Hive...")
        time.sleep(5)
        
        # Ã‰TAPE 2: Traitement des donnÃ©es
        print(f"\n{'='*80}")
        print(f"Ã‰TAPE 2: TRAITEMENT DES DONNÃ‰ES")
        print(f"{'='*80}")
        
        processing_success = self.processor.run_processing_pipeline()
        
        # Rapport final
        end_time = datetime.now()
        duration = end_time - self.start_time
        
        print(f"\n{'='*100}")
        print(f"RAPPORT FINAL DU PIPELINE")
        print(f"{'='*100}")
        print(f"Date traitÃ©e: {self.target_date}")
        print(f"DÃ©but: {self.start_time.strftime('%H:%M:%S')}")
        print(f"Fin: {end_time.strftime('%H:%M:%S')}")
        print(f"DurÃ©e totale: {duration}")
        print(f"Ã‰tape 1 (HDFS Upload): {'âœ… SuccÃ¨s' if upload_success else 'âŒ Ã‰chec'}")
        print(f"Ã‰tape 2 (Traitement): {'âœ… SuccÃ¨s' if processing_success else 'âŒ Ã‰chec'}")
        
        if upload_success and processing_success:
            print(f"\nğŸ‰ PIPELINE COMPLET TERMINÃ‰ AVEC SUCCÃˆS!")
        else:
            print(f"\nâš ï¸  PIPELINE TERMINÃ‰ AVEC DES PROBLÃˆMES")
        
        print(f"{'='*100}")
        
        return upload_success and processing_success

def main():
    """Fonction principale"""
    parser = argparse.ArgumentParser(
        description='Pipeline complet: Upload HDFS + Traitement des commandes fournisseurs',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python3 pipeline_complete.py --date 2026-01-08    # Traite une date spÃ©cifique
  python3 pipeline_complete.py                       # Traite la date d'aujourd'hui
  python3 pipeline_complete.py --upload-only        # Upload seulement
  python3 pipeline_complete.py --process-only       # Traitement seulement
        """
    )
    
    parser.add_argument('--date', 
                       default=Config.get_today(),
                       help=f'Date Ã  traiter (format: YYYY-MM-DD, dÃ©faut: aujourd\'hui)')
    
    parser.add_argument('--upload-only',
                       action='store_true',
                       help='ExÃ©cuter seulement l\'upload HDFS')
    
    parser.add_argument('--process-only',
                       action='store_true',
                       help='ExÃ©cuter seulement le traitement des donnÃ©es')
    
    parser.add_argument('--test-stock',
                       action='store_true',
                       help='Tester la structure du stock')
    
    parser.add_argument('--verbose', '-v',
                       action='store_true',
                       help='Afficher plus de dÃ©tails')
    
    args = parser.parse_args()
    
    if args.upload_only:
        # Upload HDFS seulement
        uploader = HDFSUploader(args.date)
        success = uploader.run_upload_pipeline()
        exit(0 if success else 1)
    
    elif args.process_only:
        # Traitement seulement
        processor = ProcurementGenerator(args.date)
        success = processor.run_processing_pipeline()
        exit(0 if success else 1)
    
    elif args.test_stock:
        # Tester la structure du stock
        processor = ProcurementGenerator(args.date)
        
        print("Test de la structure du stock_raw...")
        
        # Voir les premiÃ¨res lignes brutes
        query = f"SELECT * FROM hive.procurement.stock_raw WHERE date = '{args.date}' LIMIT 5"
        cmd = ['docker-compose', 'exec', '-T', 'trino', 'trino', '--execute', query]
        result = subprocess.run(cmd, capture_output=True, text=True, check=False)
        
        print("RÃ©sultat brut:")
        print(result.stdout)
        
        # Essayer diffÃ©rentes colonnes
        queries = [
            ("Test 1 - toutes colonnes", f"SELECT * FROM hive.procurement.stock_raw WHERE date = '{args.date}' LIMIT 3"),
            ("Test 2 - colonnes individuelles", f"SELECT sku_id, available_stock, reserved_stock, safety_stock FROM hive.procurement.stock_raw WHERE date = '{args.date}' LIMIT 3"),
            ("Test 3 - avec filtrage SKU", f"SELECT * FROM hive.procurement.stock_raw WHERE date = '{args.date}' AND reserved_stock LIKE 'SKU%' LIMIT 3"),
        ]
        
        for name, query in queries:
            print(f"\n{name}:")
            print(query)
            cmd = ['docker-compose', 'exec', '-T', 'trino', 'trino', '--execute', query]
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            print(result.stdout)
        
        return
    
    else:
        # Pipeline complet
        pipeline = CompletePipeline(args.date)
        success = pipeline.run()
        exit(0 if success else 1)

if __name__ == "__main__":
    main()